{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52fcce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.feature_selection import chi2 \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset1 = pd.read_csv(\"prep.csv\", index_col=None) # index_col None says there in no index column otherwise the first column is taken as index\n",
    "df2 = dataset1\n",
    "df2=pd.get_dummies(df2, drop_first=True)\n",
    "\n",
    "indep_X = df2.drop('classification_yes', 1)\n",
    "dep_Y = df2['classification_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47dc40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeFeature(indep_X, dep_Y, n ):\n",
    "    rfeList=[]\n",
    "    \n",
    "    log_model = LogisticRegression(solver='lbfgs')\n",
    "    RF = RandomForestClassifier(n_estimators = 10, criterion='entropy', random_state=0)\n",
    "    DT = DecisionTreeClassifier(criterion='gini', max_features='sqrt', splitter='best', random_state=0)\n",
    "    svc_model = SVC(kernel='linear', random_state=0)\n",
    "    NB = GaussianNB()\n",
    "    knn = KNeighborsClassifier(n_neighbors=5, metric = 'minkowski', p = 2)\n",
    "    \n",
    "    rfeModelList = [log_model, RF, svc_model, DT]\n",
    "    \n",
    "    for i in rfeModelList:\n",
    "        print(i)\n",
    "        log_rfe = RFE(i, n)#test = SelectKBest(score_func=chi2, k= n)\n",
    "        fit1 = log_rfe.fit(indep_X, dep_Y)\n",
    "        selected_columns = indep_X.columns[log_rfe.get_support()]  # Retrieve selected feature names\n",
    "        print(f\"Selected features for model {i}: {list(selected_columns)}\")  # Print the selected feature names\n",
    "\n",
    "        \n",
    "        log_rfe_feature = fit1.transform(indep_X)\n",
    "        \n",
    "        rfeList.append(log_rfe_feature)\n",
    "    return rfeList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8d82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    " def split_scalar(indep_X, dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size =0.25, random_state= 0)\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.fit_transform(X_test)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a80b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix_prediction(classifier, X_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    Accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ca6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train, y_train, X_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = confusionMatrix_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acce005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_linear(X_train, y_train, X_test):\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'linear', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = confusionMatrix_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79281c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_NL(X_train, y_train, X_test):\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'rbf', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = confusionMatrix_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeff4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Navie(X_train, y_train, X_test):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = confusionMatrix_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af531410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train, y_train, X_test):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = confusionMatrix_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102467d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision(X_train, y_train, X_test):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = confusionMatrix_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1a33f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(X_train, y_train, X_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = confusionMatrix_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba1113bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_Classification_create_Table(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf):\n",
    "    RFE_dataframe = pd.DataFrame(index=['Logistic', 'SVC', 'Random', 'DecisionTree' ], columns = ['Logistic', 'SVMl','SVMnl', 'KNN', 'Navie', 'Decision', 'Random' ])\n",
    "    print(len(acclog), len(accsvml), len(accsvmnl), len(accknn), len(accnav), len(accdes), len(accrf))\n",
    "    for number, idex in enumerate(RFE_dataframe.index):\n",
    "        RFE_dataframe['Logistic'][idex]=acclog[number]\n",
    "        RFE_dataframe['SVMl'][idex]=accsvml[number]\n",
    "        RFE_dataframe['SVMnl'][idex]=accsvmnl[number]\n",
    "        RFE_dataframe['KNN'][idex]=accknn[number]\n",
    "        RFE_dataframe['Navie'][idex]=accnav[number]\n",
    "        RFE_dataframe['Decision'][idex]=accdes[number]\n",
    "        RFE_dataframe['Random'][idex]=accrf[number]\n",
    "    return RFE_dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fba1e1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Selected features for model LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False): ['sg_c', 'sg_d', 'htn_yes']\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False)\n",
      "Selected features for model RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
      "                       warm_start=False): ['sc', 'hrmo', 'pcv']\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Selected features for model SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
      "    shrinking=True, tol=0.001, verbose=False): ['sg_d', 'dm_yes', 'appet_yes']\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=0, splitter='best')\n",
      "Selected features for model DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features='sqrt', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=0, splitter='best'): ['hrmo', 'sg_c', 'dm_yes']\n",
      "4 4 4 4 4 4 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Logistic  SVMl SVMnl   KNN Navie Decision Random\n",
       "Logistic         0.94  0.94  0.94  0.94  0.64     0.94   0.94\n",
       "SVC              0.94  0.95  0.94  0.94  0.93     0.77   0.79\n",
       "Random           0.87  0.87  0.87  0.87  0.64     0.87   0.87\n",
       "DecisionTree     0.98  0.95  0.96  0.95  0.64     0.95   0.95"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#for j in [3]:  \n",
    "rfeList = rfeFeature(indep_X, dep_Y, 3)\n",
    "acclog = [] \n",
    "accsvml= [] \n",
    "accsvmnl= []\n",
    "accknn= [] \n",
    "accnav= [] \n",
    "accdes= []\n",
    "accrf = []\n",
    "for i in rfeList:\n",
    "    X_train, X_test, y_train, y_test = split_scalar (i, dep_Y)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = logistic(X_train, y_train, X_test)\n",
    "    acclog.append(Accuracy)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = svm_linear(X_train, y_train, X_test)\n",
    "    accsvml.append(Accuracy)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = svm_NL(X_train, y_train, X_test)\n",
    "    accsvmnl.append(Accuracy)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = knn(X_train, y_train, X_test)\n",
    "    accknn.append(Accuracy)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = Navie(X_train, y_train, X_test)\n",
    "    accnav.append(Accuracy)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = Decision(X_train, y_train, X_test)\n",
    "    accdes.append(Accuracy)\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = random(X_train, y_train, X_test)\n",
    "    accrf.append(Accuracy)\n",
    "\n",
    "result = rfe_Classification_create_Table(acclog, accsvml, accsvmnl, accknn, accnav, accdes, accrf)\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77256366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the above table we can see the RFEFeature model will be using DecisionTree with K=3 and using Logistic ML algorithm the prediction is 98%\n",
    "# Selected features for model DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "#                        max_features='sqrt', max_leaf_nodes=None,\n",
    "#                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#                        min_samples_leaf=1, min_samples_split=2,\n",
    "#                        min_weight_fraction_leaf=0.0, presort=False,\n",
    "#                        random_state=0, splitter='best'): ['hrmo', 'sg_c', 'dm_yes']\n",
    "# 3 input fields are 'hrmo', 'sg', 'dm'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
